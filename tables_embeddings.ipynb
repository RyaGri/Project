{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Для обучения второй модели сделаем эмбеддинги из текстов наших постов с помощью предобученных моделей Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:29:43.250864Z",
     "iopub.status.busy": "2023-06-21T11:29:43.250503Z",
     "iopub.status.idle": "2023-06-21T11:29:55.940182Z",
     "shell.execute_reply": "2023-06-21T11:29:55.939107Z",
     "shell.execute_reply.started": "2023-06-21T11:29:43.250833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import RobertaModel  # https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaModel\n",
    "from transformers import DistilBertModel  # https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.DistilBertModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:30:10.537493Z",
     "iopub.status.busy": "2023-06-21T11:30:10.536798Z",
     "iopub.status.idle": "2023-06-21T11:30:33.628365Z",
     "shell.execute_reply": "2023-06-21T11:30:33.627152Z",
     "shell.execute_reply.started": "2023-06-21T11:30:10.537457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.6.tar.gz (383 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: psycopg2\n",
      "  Building wheel for psycopg2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psycopg2: filename=psycopg2-2.9.6-cp310-cp310-linux_x86_64.whl size=168900 sha256=879b66e8afb0416d2413272b052eaf154e9c2de99b10194388ec7c1bb23f9603\n",
      "  Stored in directory: /root/.cache/pip/wheels/a2/65/83/78e6f42d3b8e22115e894576b71799d96ab5a790b8f7bcfa85\n",
      "Successfully built psycopg2\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:33:16.190096Z",
     "iopub.status.busy": "2023-06-21T11:33:16.189498Z",
     "iopub.status.idle": "2023-06-21T11:33:19.799219Z",
     "shell.execute_reply": "2023-06-21T11:33:19.798208Z",
     "shell.execute_reply.started": "2023-06-21T11:33:16.190051Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "\n",
    "engine = create_engine(\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "    \"postgres.lab.karpov.courses:6432/startml\")\n",
    "query = 'SELECT * FROM public.post_text_df'\n",
    "\n",
    "posts_info = pd.read_sql_query(sql=text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:33:59.804183Z",
     "iopub.status.busy": "2023-06-21T11:33:59.803822Z",
     "iopub.status.idle": "2023-06-21T11:33:59.811835Z",
     "shell.execute_reply": "2023-06-21T11:33:59.810970Z",
     "shell.execute_reply.started": "2023-06-21T11:33:59.804154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Класс создаёт набор данных из токенизированных текстов.\n",
    "# Тексты токенизируется сразу же токенизатором tokenizer, при создании экземпляра класса.\n",
    "class PostDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.texts = tokenizer.batch_encode_plus(\n",
    "            texts,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        )\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.texts['input_ids'][idx], 'attention_mask': self.texts['attention_mask'][idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:34:08.557269Z",
     "iopub.status.busy": "2023-06-21T11:34:08.556886Z",
     "iopub.status.idle": "2023-06-21T11:34:08.563017Z",
     "shell.execute_reply": "2023-06-21T11:34:08.562112Z",
     "shell.execute_reply.started": "2023-06-21T11:34:08.557228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Функция для загрузки модели roberta и distilbert из huggingface\n",
    "def get_model(model_name):\n",
    "    \n",
    "    assert model_name in ['roberta', 'distilbert']\n",
    "\n",
    "    checkpoint_names = {\n",
    "        'roberta': 'roberta-base',  # https://huggingface.co/roberta-base\n",
    "        'distilbert': 'distilbert-base-cased'  # https://huggingface.co/distilbert-base-cased\n",
    "    }\n",
    "\n",
    "    model_classes = {\n",
    "        'roberta': RobertaModel,\n",
    "        'distilbert': DistilBertModel\n",
    "    }\n",
    "\n",
    "    return AutoTokenizer.from_pretrained(checkpoint_names[model_name]), model_classes[model_name].from_pretrained(checkpoint_names[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:34:16.002641Z",
     "iopub.status.busy": "2023-06-21T11:34:16.002284Z",
     "iopub.status.idle": "2023-06-21T11:34:16.009403Z",
     "shell.execute_reply": "2023-06-21T11:34:16.008436Z",
     "shell.execute_reply.started": "2023-06-21T11:34:16.002612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Подсчёт моделью эмбеддингов токенизированных текстов.\n",
    "# Эмбеддинги берутся с первого слоя last_hidden_state.\n",
    "@torch.inference_mode()\n",
    "def get_embeddings_labels(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        batch = {key: batch[key].to(device) for key in ['attention_mask', 'input_ids']}\n",
    "\n",
    "        embeddings = model(**batch)['last_hidden_state'][:, 0, :]\n",
    "\n",
    "        total_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return torch.cat(total_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:34:32.424266Z",
     "iopub.status.busy": "2023-06-21T11:34:32.423862Z",
     "iopub.status.idle": "2023-06-21T11:34:37.222148Z",
     "shell.execute_reply": "2023-06-21T11:34:37.221195Z",
     "shell.execute_reply.started": "2023-06-21T11:34:32.424239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b91af2cb7d453eb91d6cced465646b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7900cfc47a4361b0ce875510403971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2150b8197bb45f18871dd70ba1858f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32eb32733592489482c0f6d503fe1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7078f3b0458048e299b0002400640470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = get_model('distilbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:34:39.847761Z",
     "iopub.status.busy": "2023-06-21T11:34:39.847413Z",
     "iopub.status.idle": "2023-06-21T11:34:52.012280Z",
     "shell.execute_reply": "2023-06-21T11:34:52.010942Z",
     "shell.execute_reply.started": "2023-06-21T11:34:39.847730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "dataset = PostDataset(posts_info['text'].values.tolist(), tokenizer)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, collate_fn=data_collator, pin_memory=True, shuffle=False)\n",
    "batch_data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:34:58.209658Z",
     "iopub.status.busy": "2023-06-21T11:34:58.209307Z",
     "iopub.status.idle": "2023-06-21T11:35:24.272141Z",
     "shell.execute_reply": "2023-06-21T11:35:24.271144Z",
     "shell.execute_reply.started": "2023-06-21T11:34:58.209624Z"
    }
   },
   "outputs": [],
   "source": [
    "out_batch = model(**batch_data)\n",
    "print(out_batch['last_hidden_state'][:, 0, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:35:27.418369Z",
     "iopub.status.busy": "2023-06-21T11:35:27.418018Z",
     "iopub.status.idle": "2023-06-21T11:35:27.517936Z",
     "shell.execute_reply": "2023-06-21T11:35:27.516980Z",
     "shell.execute_reply.started": "2023-06-21T11:35:27.418341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:35:29.927458Z",
     "iopub.status.busy": "2023-06-21T11:35:29.927111Z",
     "iopub.status.idle": "2023-06-21T11:37:31.158290Z",
     "shell.execute_reply": "2023-06-21T11:37:31.157353Z",
     "shell.execute_reply.started": "2023-06-21T11:35:29.927429Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [02:01<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embeddings_labels(model, loader, device).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пытаемся снизить размерность и кластеризовать тексты с помощью PCA и KNN также как для первой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:37:45.832242Z",
     "iopub.status.busy": "2023-06-21T11:37:45.831542Z",
     "iopub.status.idle": "2023-06-21T11:37:46.630754Z",
     "shell.execute_reply": "2023-06-21T11:37:46.629673Z",
     "shell.execute_reply.started": "2023-06-21T11:37:45.832201Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=70)\n",
    "pca_decomp = pca.fit_transform(posts_info_PCA)\n",
    "pca_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:38:02.649277Z",
     "iopub.status.busy": "2023-06-21T11:38:02.648894Z",
     "iopub.status.idle": "2023-06-21T11:38:04.452210Z",
     "shell.execute_reply": "2023-06-21T11:38:04.450884Z",
     "shell.execute_reply.started": "2023-06-21T11:38:02.649239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistanceToCluster_0</th>\n",
       "      <th>DistanceToCluster_1</th>\n",
       "      <th>DistanceToCluster_2</th>\n",
       "      <th>DistanceToCluster_3</th>\n",
       "      <th>DistanceToCluster_4</th>\n",
       "      <th>DistanceToCluster_5</th>\n",
       "      <th>DistanceToCluster_6</th>\n",
       "      <th>DistanceToCluster_7</th>\n",
       "      <th>DistanceToCluster_8</th>\n",
       "      <th>DistanceToCluster_9</th>\n",
       "      <th>DistanceToCluster_10</th>\n",
       "      <th>DistanceToCluster_11</th>\n",
       "      <th>DistanceToCluster_12</th>\n",
       "      <th>DistanceToCluster_13</th>\n",
       "      <th>DistanceToCluster_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.375404</td>\n",
       "      <td>3.665928</td>\n",
       "      <td>3.373343</td>\n",
       "      <td>3.443877</td>\n",
       "      <td>3.622818</td>\n",
       "      <td>3.386910</td>\n",
       "      <td>1.812277</td>\n",
       "      <td>3.004539</td>\n",
       "      <td>2.834371</td>\n",
       "      <td>2.249783</td>\n",
       "      <td>3.473739</td>\n",
       "      <td>1.900510</td>\n",
       "      <td>3.408670</td>\n",
       "      <td>3.412318</td>\n",
       "      <td>3.462497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.329184</td>\n",
       "      <td>3.468094</td>\n",
       "      <td>3.325495</td>\n",
       "      <td>2.982847</td>\n",
       "      <td>3.358610</td>\n",
       "      <td>3.371622</td>\n",
       "      <td>2.184574</td>\n",
       "      <td>2.850791</td>\n",
       "      <td>2.552490</td>\n",
       "      <td>2.243558</td>\n",
       "      <td>3.248824</td>\n",
       "      <td>1.426576</td>\n",
       "      <td>3.326208</td>\n",
       "      <td>3.216277</td>\n",
       "      <td>3.136622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.398518</td>\n",
       "      <td>3.451669</td>\n",
       "      <td>3.265284</td>\n",
       "      <td>2.972764</td>\n",
       "      <td>3.367133</td>\n",
       "      <td>3.501859</td>\n",
       "      <td>1.858817</td>\n",
       "      <td>3.039336</td>\n",
       "      <td>2.885038</td>\n",
       "      <td>3.061794</td>\n",
       "      <td>3.397064</td>\n",
       "      <td>1.684046</td>\n",
       "      <td>3.358547</td>\n",
       "      <td>3.287411</td>\n",
       "      <td>3.133440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.824766</td>\n",
       "      <td>3.153519</td>\n",
       "      <td>3.513383</td>\n",
       "      <td>3.718793</td>\n",
       "      <td>3.796568</td>\n",
       "      <td>3.748973</td>\n",
       "      <td>2.461983</td>\n",
       "      <td>3.278253</td>\n",
       "      <td>3.374481</td>\n",
       "      <td>3.411346</td>\n",
       "      <td>4.065657</td>\n",
       "      <td>2.435080</td>\n",
       "      <td>3.739384</td>\n",
       "      <td>3.696885</td>\n",
       "      <td>3.790943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.040599</td>\n",
       "      <td>3.164101</td>\n",
       "      <td>3.033904</td>\n",
       "      <td>2.641305</td>\n",
       "      <td>3.048451</td>\n",
       "      <td>2.803077</td>\n",
       "      <td>1.463832</td>\n",
       "      <td>2.642233</td>\n",
       "      <td>2.137744</td>\n",
       "      <td>2.950977</td>\n",
       "      <td>3.241409</td>\n",
       "      <td>2.114441</td>\n",
       "      <td>2.807246</td>\n",
       "      <td>2.842687</td>\n",
       "      <td>2.775343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DistanceToCluster_0  DistanceToCluster_1  DistanceToCluster_2  \\\n",
       "0             2.375404             3.665928             3.373343   \n",
       "1             2.329184             3.468094             3.325495   \n",
       "2             2.398518             3.451669             3.265284   \n",
       "3             2.824766             3.153519             3.513383   \n",
       "4             2.040599             3.164101             3.033904   \n",
       "\n",
       "   DistanceToCluster_3  DistanceToCluster_4  DistanceToCluster_5  \\\n",
       "0             3.443877             3.622818             3.386910   \n",
       "1             2.982847             3.358610             3.371622   \n",
       "2             2.972764             3.367133             3.501859   \n",
       "3             3.718793             3.796568             3.748973   \n",
       "4             2.641305             3.048451             2.803077   \n",
       "\n",
       "   DistanceToCluster_6  DistanceToCluster_7  DistanceToCluster_8  \\\n",
       "0             1.812277             3.004539             2.834371   \n",
       "1             2.184574             2.850791             2.552490   \n",
       "2             1.858817             3.039336             2.885038   \n",
       "3             2.461983             3.278253             3.374481   \n",
       "4             1.463832             2.642233             2.137744   \n",
       "\n",
       "   DistanceToCluster_9  DistanceToCluster_10  DistanceToCluster_11  \\\n",
       "0             2.249783              3.473739              1.900510   \n",
       "1             2.243558              3.248824              1.426576   \n",
       "2             3.061794              3.397064              1.684046   \n",
       "3             3.411346              4.065657              2.435080   \n",
       "4             2.950977              3.241409              2.114441   \n",
       "\n",
       "   DistanceToCluster_12  DistanceToCluster_13  DistanceToCluster_14  \n",
       "0              3.408670              3.412318              3.462497  \n",
       "1              3.326208              3.216277              3.136622  \n",
       "2              3.358547              3.287411              3.133440  \n",
       "3              3.739384              3.696885              3.790943  \n",
       "4              2.807246              2.842687              2.775343  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 15\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(pca_decomp)\n",
    "\n",
    "posts_info['TextCluster'] = kmeans.labels_\n",
    "\n",
    "dists_columns = [f'DistanceToCluster_{i}' for i in range(n_clusters)]\n",
    "\n",
    "dists_df = pd.DataFrame(\n",
    "    data=kmeans.transform(pca_decomp),\n",
    "    columns=dists_columns\n",
    ")\n",
    "\n",
    "dists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:38:17.017732Z",
     "iopub.status.busy": "2023-06-21T11:38:17.017375Z",
     "iopub.status.idle": "2023-06-21T11:38:17.024560Z",
     "shell.execute_reply": "2023-06-21T11:38:17.023403Z",
     "shell.execute_reply.started": "2023-06-21T11:38:17.017703Z"
    }
   },
   "outputs": [],
   "source": [
    "posts_info = pd.concat((posts_info, dists_df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим признаки для второй модели на сервер "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T11:47:52.091854Z",
     "iopub.status.busy": "2023-06-21T11:47:52.091471Z",
     "iopub.status.idle": "2023-06-21T11:47:52.128097Z",
     "shell.execute_reply": "2023-06-21T11:47:52.126877Z",
     "shell.execute_reply.started": "2023-06-21T11:47:52.091823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>DistanceToCluster_0</th>\n",
       "      <th>DistanceToCluster_1</th>\n",
       "      <th>DistanceToCluster_2</th>\n",
       "      <th>DistanceToCluster_3</th>\n",
       "      <th>DistanceToCluster_4</th>\n",
       "      <th>DistanceToCluster_5</th>\n",
       "      <th>DistanceToCluster_6</th>\n",
       "      <th>DistanceToCluster_7</th>\n",
       "      <th>DistanceToCluster_8</th>\n",
       "      <th>DistanceToCluster_9</th>\n",
       "      <th>DistanceToCluster_10</th>\n",
       "      <th>DistanceToCluster_11</th>\n",
       "      <th>DistanceToCluster_12</th>\n",
       "      <th>DistanceToCluster_13</th>\n",
       "      <th>DistanceToCluster_14</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>2.375404</td>\n",
       "      <td>3.665928</td>\n",
       "      <td>3.373343</td>\n",
       "      <td>3.443877</td>\n",
       "      <td>3.622818</td>\n",
       "      <td>3.386910</td>\n",
       "      <td>1.812277</td>\n",
       "      <td>3.004539</td>\n",
       "      <td>2.834371</td>\n",
       "      <td>2.249783</td>\n",
       "      <td>3.473739</td>\n",
       "      <td>1.900510</td>\n",
       "      <td>3.408670</td>\n",
       "      <td>3.412318</td>\n",
       "      <td>3.462497</td>\n",
       "      <td>UK economy facing major risks\\n\\nThe UK manufa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>2.329184</td>\n",
       "      <td>3.468094</td>\n",
       "      <td>3.325495</td>\n",
       "      <td>2.982847</td>\n",
       "      <td>3.358610</td>\n",
       "      <td>3.371622</td>\n",
       "      <td>2.184574</td>\n",
       "      <td>2.850791</td>\n",
       "      <td>2.552490</td>\n",
       "      <td>2.243558</td>\n",
       "      <td>3.248824</td>\n",
       "      <td>1.426576</td>\n",
       "      <td>3.326208</td>\n",
       "      <td>3.216277</td>\n",
       "      <td>3.136622</td>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id     topic  DistanceToCluster_0  DistanceToCluster_1  \\\n",
       "0        1  business             2.375404             3.665928   \n",
       "1        2  business             2.329184             3.468094   \n",
       "\n",
       "   DistanceToCluster_2  DistanceToCluster_3  DistanceToCluster_4  \\\n",
       "0             3.373343             3.443877             3.622818   \n",
       "1             3.325495             2.982847             3.358610   \n",
       "\n",
       "   DistanceToCluster_5  DistanceToCluster_6  DistanceToCluster_7  \\\n",
       "0             3.386910             1.812277             3.004539   \n",
       "1             3.371622             2.184574             2.850791   \n",
       "\n",
       "   DistanceToCluster_8  DistanceToCluster_9  DistanceToCluster_10  \\\n",
       "0             2.834371             2.249783              3.473739   \n",
       "1             2.552490             2.243558              3.248824   \n",
       "\n",
       "   DistanceToCluster_11  DistanceToCluster_12  DistanceToCluster_13  \\\n",
       "0              1.900510              3.408670              3.412318   \n",
       "1              1.426576              3.326208              3.216277   \n",
       "\n",
       "   DistanceToCluster_14                                               text  \n",
       "0              3.462497  UK economy facing major risks\\n\\nThe UK manufa...  \n",
       "1              3.136622  Aids and climate top Davos agenda\\n\\nClimate c...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_info.head(2)\n",
    "posts_info.to_sql(\"ryabgri_post_inf_features_emb_3\", con=engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
